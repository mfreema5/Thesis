#### How can researchers be “ahead of the curve” in evaluations of research impact?

Even when not officially required, demonstrations of the practical impact of research can be a useful addition in any context when there is an evaluation of the value of research.  Documenting or demonstrating impact can also be internally helpful, as “in doing so a great majority will derive insight and local benefits” (Technopolis 2010)

The Technopolis report on feedback from the HEFCE-REF pilot includes a lot that would seem to recommend that researchers develop a portfolio of research impact *before* it's required of them.  Participants in the pilot exercise reported that, “It did cause departments to take a fresh look at their work, and it shed new light on the breadth of good things that have happened in part as a result of the excellent research being carried out. It has helped people to reflect on their wider contributions…”. The irony in the report is that “The exercise has also revealed how little we do know about the use that is made of our research and equally that where one has a sense of good things happening, we simply don’t record that anywhere. Our evidence base is pretty scant”. This irony is echoed a number of times: research institutions were unaware of the wider impact they were having despite that impact being real and positive.  E.g., “we were pleasantly surprised at the outcome of the case studies. These clearly provided a much broader appreciation of the impact the university’s research has had / is having than previously recognised” (Technopolis 2010).

If the report is correct in that there is a “growing interest in the notion of research impact, evident amongst all funders” (Technopolis 2010), then the best way to avoid the irony experienced by participating institutions and researchers in the REF pilot exercise, is for researchers to not wait until a similar exercised is forced upon them.

Perhaps the ongoing-experiences of the HEFCE and the institutions that it covers, along with the experiences of programs such as ‘Evaluating Research in Context’ (ERiC) in the Netherlands (Spaapen *et al.* 2007), should be used as a basis to create a set of “best practices” for use by researchers not yet covered by any practical-impact requirements to do self-assessments, and potentially by funding institutions as a starting point for including practical impact in their evaluation of research.


----

### References

* Technopolis Ltd. 2010. *REF Research Impact Pilot Exercise Lessons-Learned Project: Feedback on Pilot Submissions.* Higher Education Funding Council for England. http://www.ref.ac.uk/pubs/refimpactpilotlessons-learnedfeedbackonpilotsubmissions/.
* Spaapen, J.B, H Dijstelbloem, and F.J.M Wamelink. 2007. *Evaluating Research in Context: A Method for Comprehensive Assessment.* The Hague: Consultative Committee of Sector Councils for Research and Development (COS).
