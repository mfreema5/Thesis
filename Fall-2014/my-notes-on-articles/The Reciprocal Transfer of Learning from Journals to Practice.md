Latham, Gary. 2001. “The Reciprocal Transfer of Learning from Journals to Practice.” Applied Psychology: An International Review 50 (2): 201–11.  doi:10.1111/1464-0597.00054




> Why have you stopped reading them?

> 1. Lack of time. Academics are paid to read; they are paid to teach and do research on the basis of what is in the journals. Practitioners are paid solely to practice. But not to read is to accelerate professional obsolescence; it ensures uninformed practice (Latham & Latham, 2000). Regardless of whether the content domain is selection, performance management, training, or motivation, answers to questions to issues presented to me by senior management and union executives were found easily by me in the journals.

  “found easily by me in the journals” – But is it easy for anyone, not just you?  And are some journals more easily searched for answers than others?  (Because of jargon and ‘academical’ writing.)

> 2. Transfer of learning from the journals to practice is difficult and even clumsy when trying to go from one finding or one insight to a specific application; it is not easy to put two or three findings or observations together to generate something that is more than the piece or pieces with which you started. This is true. But this explanation is no different in psychology than it is in medicine. A thrill in research is the same thrill in practice, only in the latter it is greater than in the former because in practice one can see the positive differences an application or intervention makes to the lives of others. The thrill is the art of discovery; a discovery that 1+1+1 = 4 or greater.

  Perhaps the author mis-understands the reason for the difficulty.  It may be that research results are not presented in a way that is easily mapped to practice.  Or perhaps the research results are so narrowly defined that they aren't applicable to the vast majority of practitioners.

> 3. The organisation and the participant sample are different from the ones with whom I am working. This explanation for the lack of transfer from journals to practice confuses transfer of learning on the basis of identical elements with that of common principles. Just as a good cook reads a recipe and makes changes to develop something new and appropriate for dinner guests, a good practitioner reads a scientific journal and makes changes to develop something new and appropriate for the client organisation. Theory provides a framework and a rationale for implementing a set of ideas; the procedure section of a journal article makes explicit the ways to do so. As for identical elements, Locke (1986), in an edited book, showed that findings from one sample (e.g. college students) generalise to samples from other populations in most areas of organisational psychology. Moreover, most journal editors are receptive to submissions that deal with external validity. Practitioners can enhance knowledge in psychology by discovering that what is found in one country, one organisation, or one participant sample generalises or fails to generalise to others.

  “The organisation and the participant sample are different from the ones with whom I am working. …confuses transfer of learning on the basis of identical elements with that of common principles.”  Or maybe the research is failing to properly explain the “common principles” involved.  Or perhaps the finds really are narrowly confined to a rare subset.


> 4. Practitioners reject journals that reject them. They are not alone in this behaviour; academics do likewise. Given rejection rates of 75 per cent or higher in psychology journals, publication has never been an easy process. But this rejection rate increases the probability that that which is published is of sufficient rigor that the results are replicable by others. Replication is the sine qua non of both practice and science. The rigor with which the methodology must be reported and the results substantiated minimises the probability of a type 1 error.

  “But this rejection rate increases the probability that that which is published is of sufficient rigor that the results are replicable by others.”  No.  A process that does the latter with also do the former, but doing the former does *not* ensure the latter.

  “The rigor with which the methodology must be reported and the results substantiated minimises the probability of a type 1 error.”  And increases the probability of a Type-II error.


> 5. The journal topics are too narrow. More concern is spent on minimizing the confounding of independent variables than on influencing the dependent variable. The solutions to this concern are at least three-fold. First, psychology has accumulated a vast amount of knowledge in the 20th century on the effects of isolated independent variables on asundry dependent variables. In the 21st century, it is time to combine independent variables in the form of treatment packages similar to that which is done in medicine to significantly improve the health of the individual. Second, practitioners need to author these articles. Concerns with confounding can be dealt with in references in the introduction of the journal article to the studies that show the effects of each variable independently. The purpose of this new article is to study the effects of these variables when they are combined. The field awaits this contribution to the journals from practitioners (Latham & Latham, 2000). Third, academics and practitioners need to collaborate fully in trying to understand a phenomenon, and to identifying and explaining ways to overcoming barriers to implementation. Both parties must be open to challenge and inquiry from the other (Latham & Latham, 2000).

  This comes up repeatedly here: Are articles exploring common principles, or narrow slices of trivia?

  This is a consequence of the criteria for publication.  NHST promotes examining narrow slices of trivia.  Maybe there are other things that do, also.  Either way, the are we arguing that practitioners *should* read the journals, or that the journals should publish the articles that practitioners want to read?


“The implicit theory underlying this manuscript is that practitioners have as much to contribute to and benefit from the journals as do their academic counterparts.”  And yet practitioners are not included in the decision-making process as to what gets published.

Did peer-review kill research?





