

Researchers abuse NHST by researching any correlation that's statistically “significant”, ignoring all other attributes of the correlation.

How can we prevent/correct this abuse of NHST?

Include the effect size along with the statistical significance in judging the importance of a correlation.

However, the effect size of a correlation is not always easy to measure or even estimate.  Strong, statistically significant correlations can have negligible effects; weak, barely significant correlations can result in huge effects.  (Find Cohen quote.)

One way to estimate whether or not the effect size of a correlation is large enough to be worth pursuing is to ask, “Would a practitioner care about this size of an effect in this correlation?”

We can expand and yet simplify the question “What effect size in which correlations would a practitioner care about?” into “What research would a practitioner care about?”

And the easiest way to know if a practitioner would care, is to ask a practitioner.

But witnesses are unreliable; practitioners may give skewed responses to questions about what research they care about for any number of reasons.  A better approach to discover what research practitioners care about is to find out what research is being used by practitioners, and what research are they discussing among themselves.

When practitioners use research results in their practice, or discuss them with other practitioners, we'll say that the research had a “practical impact”, to distinguish from “scientific impact” or “citation impact”.

We could follow the lead of citation metrics, and especially of altmetrics, and compile all the practical impacts into a “practical impact metric”.

For what purpose could a “practical impact metric” be used?

Requiring practical impact is problematic; however, institutions could reward researchers based on the practical impact of their research.

If research with practical impact gets rewarded, and research without practical impact does not, then researchers are going to prefer to work on research that may have practical impact.

Part of identifying which research may have practical impact is to consider the size of the effect that it may have, in addition to it's potential to achieve statistical significance.

So, while the potential for statistical significance would still be sought after in studies, it would not be the only, or the most important thing.  Research likely to reveal a statistically significant correlation with a trivial effect size would be set aside.


+++++

A practical impact metric would give researchers a tool to differentiate between research based on the potential for importance, instead of differentiating based only on the potential for statistical significance.

At the same time, a practical impact metric would give institutions a tool to encourage researchers to focus on research that has potential for importance, instead of focusing on a potential for statistical significance.

With a practical impact metric, researchers would have both the means and the motivation to maximize the potential for importance of their research, in addition to its maximizing its potential for publication.



