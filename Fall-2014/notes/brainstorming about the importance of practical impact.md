
##Brainstorming about the importance ‘practical impact’

* “Pure science” vs. “Practical impact”

* Independence of researchers
  * What determines funding determines what research gets done. :bulb:

Dictionaries: are they descriptive or prescriptive?  (Intended to be descriptive, often used as prescriptive.)

Should research be descriptive or prescriptive?

If it is descriptive, should unimportant things be described?


Practical impact *should* affect future research.

Practical impact is proof that you understood the questions and concerns of practitioners.

----

> “*Poorly communicated knowledge has little value.*”

* For research to have practical impact, it must:
  1. Comprise relevant phenomenon (things people actually care about)
  1. Explain a useful portion of variation (as opposed to splitting hairs)
  1. Clearly and completely communicate the findings, *in a way that practitioners can understand* (if they can't understand it, they can't use it)
  1. Be “discoverable” by practitioners (if they can't find it, they can't read it)


Looking at those in reverse order:

* **Discovery**
  * Making research discoverable by practitioners makes it more discoverable by researchers, too.

* **Clarity**
  * Researchers would also benefit from requiring that research be present in a more easily accessible form.
  * Improved clarity would ease cross-discipline knowledge transfer.
  * Higher clarity requirements would likely be a indirect measure of how “far out in left field” a piece of research is; the more obscure the topic, the more difficult it would be to present it to people outside the area.

* **Effect size**
  * “Statistical significance” is a measure of the probability that an observed correlation is the result of random chance.  It's the probability that the correlation is “real”.  But just because a correlation is real, that doesn't necessary mean that it's large enough to be *important*.
    * If you can explain a 1-day variation in the average person's lifespan, no one cares.  * If you can explain a 10-year variation in the average person's lifespan, you're going to be rich *and* famous.
  * This is where researchers jump ship, because statistical significance is much easier than interpreting effect sizes.
    * Determining statistical significance is largely a mechanic process.  While deciding which methods to use involves some ambiguity, the rest is just calculations.
    * Effect sizes cannot be easily compared between phenomenon, because not all phenomenon are equal.  Explaining 5% of the variation in hair loss is not nearly as important as explaining 5% of the variation in infant mortality.
    * Effect sizes cannot be examined mechanically.  They require interpretation and are always somewhat ambiguous.  They are not as easily quantified as statistical significance.

* **Relevance**
  * Just because a relationship is real and large, that doesn't mean it matters to anyone.
  * This is intermingled with effect size.
    * A large enough effect size can overcome low relevance.
    * A very small effect size combined with high relevance becomes important.
  * Again, this is open to interpretation and ambiguous, so researchers will shy away from it.
    * However, this ambiguity is a good reason to measure practical impact.

----

----

----


Non-experimental research
  How are social sciences and the like different from “hard” sciences?  Is there some better term than ‘experimental’?

Non-testable hypotheses
  In the sense of designing experiments?  But you can, just not very well controlled ones.  I'm not sure were I was going with this.











Poorly communicated knowledge has little value.


