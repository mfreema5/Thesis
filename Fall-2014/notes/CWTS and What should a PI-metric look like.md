#CWTS and practical impact

On the CWTS website I didn't find any tools or reports or the like that covers “practical impact” as I've been envisioning it so far.  The apparently have a ‘commercial divison’ of sorts, CWTS B.V., that will provide research statistics to firms.  Though I get the impression that it does more training/education than providing of analysis reports or data packages.

But going over the papers available on the site, I finally got around to reading through “Who Reads Research Articles? An Altmetrics Analysis of Mendeley User Categories” (Mohammadi *et al.*, 2014).  And it seems like it might be a gold mine of references in the fields of bibliometrics and scientometrics that are relevant to my interests.  So, I'm thinking that I might need to go back and do another iteration through the existant literature.

There appears to be research, as yet undiscovered by me, on the difference between “reading” and “citing” research, and why using only citation metrics can therefore misrepresent the impact of a paper.  “Pure readers” may be using papers for practical application, or for teaching, which should probably count as some sort of “practical impact”, since the students who are taught some piece of research are much more likely to employ it later than they are research that languishes in a journal somewhere.

Up until now I had been stuck thinking about altmetrics as being citations, but not in academic journals.  The Mohammadi *et al.* (2014) paper goes a completely different route, looking at the readership data from Mendeley.  This is not a novel approach&mdash;the authors reference a number of other papers that do similar analyses, using various “webometrics” applied to various websites or content-management packages.  I'd always had a feeling that there was a body of research relevant to my thesis lurking out there in the infometrics field, but I didn't think I had any good way of getting to it.  This paper might be the entrance I need.

So, anyway, it doesn't seem like CWTS is already doing what I'm proposing.  Though it's definitely related to at least some of their research goals.

#What should a ‘practical impact’ metric look like?

###If you don't reward a behavior, people won't engage in it.  If you don't properly measure a behavior, you can't properly reward it.

What should a “practical impact” metric look like?  I don't think it's feasible to have just one.  Not only are there a number of different paths to identifying practical impact—citation-like events, readership data, teaching-related data, etc.—but there may be no way to make quantitative comparisons between different practical impacts.  Much like the effect of “citation cultures” on citation metrics, not only will practical impacts from different paths be largely incomparable, but the context of the impact will make a large difference in its “societal value” (for lack of a better term).

Narrowing the focus of my thesis down to one sort, in one field might make for a useful example of the concept.  Though, I don't know if I need decide on what the example should be right now.  I'm still more interested—or, rather, I think theres's more value to be had, in exploring the concept of measuring practical impact.

I want to flesh out the notion that practical impact needs to be considered separately from other sorts of impact.  I still find it odd that altmetrics are being “validated” by examining their correlation to existing metrics.

Is practical impact as an extension of other metrics, or an adjunct?  Where others want to show correlations between existing metrics and altmetrics, I want to demonstrate that practical impact is an independent quality that is *not* being properly captured in citation metrics, and is therefore being ignored.

So, pick some field, pick some path to measuring practical impact, generate the numbers for some class of papers.  Then compare them to existing metrics.  How?  What do I expect to see?


#HEFCE – REF

Oh, and there's some UK government initiative (HEFCE – Research Excellence Framework) concerning funding science that is apparently asking questions about “practical impact” and related issues of “societal value”.  I should probably at least do a fly-by on that, as an additional justification on why we should care.


----

#Reference

Mohammadi, Ehsan, Mike Thelwall, Stefanie Haustein, and Vincent Larivière. 2014. “Who Reads Research Articles? An Altmetrics Analysis of Mendeley User Categories.” *Journal of the Association for Information Science and Technology*, in press.
