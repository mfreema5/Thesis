#CWTS and practical impact

On the CWTS website I didn't find any tools or reports or the like that covers “practical impact” as I've been envisioning it so far.  The apparently have a ‘commercial divison’ of sorts, CWTS B.V., that will provide research statistics to firms.  Though I get the impression that it does more training/education than providing of analysis reports or data packages.  (See: [CWTS webpages](Fall-2014/notes/CWTS-webpages.md).)

But while going over the papers available on the site, I finally got around to reading through “Who Reads Research Articles? An Altmetrics Analysis of Mendeley User Categories” (Mohammadi *et al.*, 2014).  And it would seem to be a gold mine of references in the fields of bibliometrics and scientometrics, which are relevant to my interests.  So, I'm thinking that I might need to go back and do another iteration through the existant literature.

Among other things of possible interest, there appears to be research (as yet undiscovered by me) on the differences between “reading” and “citing” activities, and why using only citation metrics can therefore misrepresent the over-all impact of a paper.  “Pure readers” will use papers for practical application, or teaching&mdash;which should probably count as some sort of “practical impact”, since the students who are taught some piece of research are much more likely to employ it later than they are research that languishes in a journal somewhere.

Up until now I had been mentally stuck in thinking about altmetrics as being just another form of citations, but ones that are not in academic journals.  The Mohammadi *et al.* (2014) paper goes a completely different route, looking at readership data from Mendeley.  That is not to say that theirs is a novel approach&mdash;they reference a number of other papers that do similar analyses, using various “webometrics” applied to various websites or content-management packages.  I'd always had a feeling that there was a body of research relevant to my thesis lurking out there in the infometrics field, but I didn't have any good way of getting to it.  This paper might be the entrance I need.

So, anyway, back to the point at hand: it doesn't seem like CWTS is already doing what I'm proposing.  Though it's definitely related to many of their research goals.

#What should a ‘practical impact’ metric look like?

***If you don't reward a behavior, people won't engage in it.  And if you don't properly measure a behavior, you can't properly reward it.***

What should a “practical impact” metric look like?  I don't think it's feasible to have just one.  Not only are there a number of different paths to identifying either practical impact citation-like events, readership data, or teaching-related data, etc., but there may be no way to make quantitative comparisons between different practical impacts.  Much like the effect of “citation cultures” on citation metrics, not only will practical impacts from different paths be largely incomparable, but the context of the impact will make a large difference in its “societal value” (for lack of a better term).

Narrowing the focus of my thesis down to one sort, in one field might make it possible to generate something as an example of the concept.  Though, I don't know if I need decide on what the example should be right now.  More importantly, I'm still more interested in—or, rather, I think theres's more value to be had from—exploring and defining the concept of measuring practical impact.

Meaning, I think it will be more useful to flesh out the notion that practical impact needs to be considered separately from other sorts of impact.  I still find it odd that altmetrics are being “validated” by examining their correlation to existing metrics.

Is practical impact an extension of other metrics, or an adjunct?  Where others want to show correlations between existing metrics and altmetrics, I want to demonstrate that practical impact is an independent quality that is *not* being properly captured in citation metrics, and is therefore being ignored.

So maybe: pick some field, pick some path to measuring practical impact, generate the numbers for some class of papers.  Then compare them to existing metrics.  How?  What do I expect to see?  Zero correlation would be odd—how can something have practical impact but no citation-based impact?  Perfect correlation would make me wonder if I was really measuring something independent of citations.  Maybe I need to go refresh my spotty memory of statistical theory.


##Sidebar: HEFCE – REF

There's some UK government initiative (HEFCE – Research Excellence Framework) concerning funding science that is apparently asking questions about “practical impact” and related issues of “societal value”.  I should probably at least do a fly-by on that, as an additional justification on why we should care.

###Some links:

* [Research Excellence Framework](http://www.ref.ac.uk/) (official)
  * [Assessment criteria and level definitions](http://www.ref.ac.uk/panels/assessmentcriteriaandleveldefinitions/)
  * [Expert panels](http://www.ref.ac.uk/panels/)
  * [Information for research users](http://www.ref.ac.uk/users/)


####REF2014: A brief guide for research users

From the PDF of the same name.

>**The impact of research** &ndash; The REF will for the first time explicitly assess the impact of research beyond academia, as well as assessing the academic excellence of research. One purpose of the REF is to reward research departments in universities that engage with business, the public sector and civil society organisations, and carry new ideas through to beneficial outcomes

>*Universities are responsible for gathering and submitting evidence of the impact of their research*. Each submission must include:

>• Case studies of impacts that took place during 2008-2013. The underpinning research must be of high quality, and carried out by the university since 1993. 

>• An impact strategy to set out how the university engages with users and facilitates impact from its research.

>Impact will be assessed jointly by academics and **research users** on the REF expert panels. All of the expert panels include some research users.

>**What do we mean by ‘impact’?**

>The benefits that can flow from excellent research are many and varied. For the purposes of the REF, impact is defined as: *“any effect on, change or benefit to the economy, society, culture, public policy or services, health, the environment or quality of life, beyond academia.”*

####Publication of other REF material

See: [Arrangements for the publication of results](http://www.ref.ac.uk/pubs/arrangementsforthepublicationofresults/).

>In early 2015, we will publish the submissions on the REF website. For each submission we will publish: a separate list of staff and outputs; the submitted case studies and impact template; and the submitted environment data and template. We will remove personal and contractual details of staff, and any other data that the HEI has indicated should not be published for commercial sensitivity or other reasons. HEIs have had the opportunity to provide redacted versions of case studies, impact templates and environment templates for the purpose of publication.

####REF Impact Pilot

Even better: 

>The [Imperial College London] participated in the HEFCE pilot to assess how impact might be measured in the REF.

To do: check out [the ICL webpage](http://www3.imperial.ac.uk/planning/strategicprojects/researchassessment/development/impactpilot) for PDFs of example cases.   And maybe track down more of such things.


----

##Reference

Mohammadi, Ehsan, Mike Thelwall, Stefanie Haustein, and Vincent Larivière. 2014. “Who Reads Research Articles? An Altmetrics Analysis of Mendeley User Categories.” *Journal of the Association for Information Science and Technology*, in press.
